<!DOCTYPE html><html lang="ko"><head>
  <!-- hexo-inject:begin --><!-- hexo-inject:end --><meta charset="UTF-8">
<meta name="viewport" content="width=device-width, initial-scale=1, maximum-scale=2">
<meta name="theme-color" content="#222">
<meta name="generator" content="Hexo 5.0.2">
  <link rel="apple-touch-icon" sizes="180x180" href="/images/apple-touch-icon-next.png">
  <link rel="icon" type="image/png" sizes="32x32" href="/images/favicon-32x32-next.png">
  <link rel="icon" type="image/png" sizes="16x16" href="/images/favicon-16x16-next.png">
  <link rel="mask-icon" href="/images/logo.svg" color="#222">






  

<script class="hexo-configurations">
    var NexT = window.NexT || {};
    var CONFIG = {"hostname":"ejpark78.github.io","root":"/","scheme":"Gemini","version":"8.0.0-rc.5","exturl":false,"sidebar":{"position":"right","display":"post","padding":18,"offset":12},"copycode":true,"bookmark":{"enable":false,"color":"#222","save":"auto"},"fancybox":false,"mediumzoom":false,"lazyload":false,"pangu":false,"comments":{"style":"tabs","active":null,"storage":true,"lazyload":false,"nav":null},"motion":{"enable":true,"async":false,"transition":{"post_block":"fadeIn","post_header":"fadeInDown","post_body":"fadeInDown","coll_header":"fadeInLeft","sidebar":"fadeInUp"}},"prism":false};
  </script>

  <meta name="description" content="12345678910111213141516171819202122232425262728293031323334353637383940414243444546from gensim import modelsimport spacyfrom gensim import corpora documents = [    u&quot;Football club Arsenal defeat">
<meta property="og:type" content="article">
<meta property="og:title" content="자연어 처리와 컴퓨터 언어학">
<meta property="og:url" content="https://ejpark78.github.io/ckf3rmlfm003ak78oaqwe063g.html">
<meta property="og:site_name" content="오늘은 뭘 배우셨나요?">
<meta property="og:description" content="12345678910111213141516171819202122232425262728293031323334353637383940414243444546from gensim import modelsimport spacyfrom gensim import corpora documents = [    u&quot;Football club Arsenal defeat">
<meta property="og:locale">
<meta property="article:published_time" content="2020-08-18T12:36:52.000Z">
<meta property="article:modified_time" content="2020-08-19T23:15:20.707Z">
<meta property="article:author" content="Park Eunjin">
<meta property="article:tag" content="공부">
<meta property="article:tag" content="자연어 처리와 컴퓨터 언어학">
<meta name="twitter:card" content="summary">


<link rel="canonical" href="https://ejpark78.github.io/ckf3rmlfm003ak78oaqwe063g.html">


<script data-pjax="" class="page-configurations">
  // https://hexo.io/docs/variables.html
  CONFIG.page = {
    sidebar: "",
    isHome : false,
    isPost : true,
    lang   : 'study'
  };
</script>

  <title>자연어 처리와 컴퓨터 언어학 | 오늘은 뭘 배우셨나요?</title>
  






  <noscript>
  <style>
  body { margin-top: 2rem; }

  .use-motion .menu-item,
  .use-motion .sidebar,
  .use-motion .post-block,
  .use-motion .pagination,
  .use-motion .comments,
  .use-motion .post-header,
  .use-motion .post-body,
  .use-motion .collection-header {
    visibility: visible;
  }

  .use-motion .header,
  .use-motion .site-brand-container .toggle,
  .use-motion .footer { opacity: initial; }

  .use-motion .site-title,
  .use-motion .site-subtitle,
  .use-motion .custom-logo-image {
    opacity: initial;
    top: initial;
  }

  .use-motion .logo-line {
    transform: scaleX(1);
  }

  .search-pop-overlay, .sidebar-nav { display: none; }
  .sidebar-panel { display: block; }
  </style>
</noscript><!-- hexo-inject:begin --><!-- hexo-inject:end -->

<script>function loadCss(l){var d=document,h=d.head,s=d.createElement('link');s.rel='stylesheet';s.href=l;!function e(f){if (d.body)return f();setTimeout(function(){e(f)})}(function(){h.appendChild(s);});}loadCss('/style.css');loadCss('//cdn.jsdelivr.net/npm/@fortawesome/fontawesome-free@5.14.0/css/all.min.css');loadCss('//cdn.jsdelivr.net/npm/animate.css@3.1.1/animate.min.css');</script><noscript><link rel="stylesheet" href="/style.css"><link rel="stylesheet" href="//cdn.jsdelivr.net/npm/@fortawesome/fontawesome-free@5.14.0/css/all.min.css"><link rel="stylesheet" href="//cdn.jsdelivr.net/npm/animate.css@3.1.1/animate.min.css"></noscript></head>

<body itemscope="" itemtype="http://schema.org/WebPage" class="use-motion">
  <!-- hexo-inject:begin --><!-- hexo-inject:end --><div class="headband"></div>

  <main class="main">
    <header class="header" itemscope="" itemtype="http://schema.org/WPHeader">
      <div class="header-inner"><div class="site-brand-container">
  <div class="site-nav-toggle">
    <div class="toggle" aria-label="Toggle navigation bar">
        <span class="toggle-line"></span>
        <span class="toggle-line"></span>
        <span class="toggle-line"></span>
    </div>
  </div>

  <div class="site-meta">

    <a href="/" class="brand" rel="start">
      <i class="logo-line"></i>
      <h1 class="site-title">오늘은 뭘 배우셨나요?</h1>
      <i class="logo-line"></i>
    </a>
      <p class="site-subtitle" itemprop="description">나도 블로그가 있다!!!</p>
  </div>

  <div class="site-nav-right">
    <div class="toggle popup-trigger">
    </div>
  </div>
</div>



<nav class="site-nav">
  <ul class="main-menu menu">
        <li class="menu-item menu-item-home">

    <a href="/" rel="section"><i class="fa fa-home fa-fw"></i>홈</a>

  </li>
        <li class="menu-item menu-item-tags">

    <a href="/tags/" rel="section"><i class="fa fa-tags fa-fw"></i>태그<span class="badge">60</span></a>

  </li>
        <li class="menu-item menu-item-categories">

    <a href="/categories/" rel="section"><i class="fa fa-th fa-fw"></i>카테고리<span class="badge">63</span></a>

  </li>
        <li class="menu-item menu-item-archives">

    <a href="/archives/" rel="section"><i class="fa fa-archive fa-fw"></i>아카이브<span class="badge">53</span></a>

  </li>
  </ul>
</nav>




</div>
        
  
  <div class="toggle sidebar-toggle">
    <span class="toggle-line"></span>
    <span class="toggle-line"></span>
    <span class="toggle-line"></span>
  </div>

  <aside class="sidebar">

    <div class="sidebar-inner sidebar-overview-active">
      <ul class="sidebar-nav">
        <li class="sidebar-nav-toc">
          목차
        </li>
        <li class="sidebar-nav-overview">
          흝어보기
        </li>
      </ul>

      <!--noindex-->
      <section class="post-toc-wrap sidebar-panel">
      </section>
      <!--/noindex-->

      <section class="site-overview-wrap sidebar-panel">
        <div class="site-author animated" itemprop="author" itemscope="" itemtype="http://schema.org/Person">
  <p class="site-author-name" itemprop="name">Park Eunjin</p>
  <div class="site-description" itemprop="description">적자생존!</div>
</div>
<div class="site-state-wrap animated">
  <nav class="site-state">
      <div class="site-state-item site-state-posts">
          <a href="/archives/">
        
          <span class="site-state-item-count">53</span>
          <span class="site-state-item-name">포스트</span>
        </a>
      </div>
      <div class="site-state-item site-state-categories">
            <a href="/categories/">
          
        <span class="site-state-item-count">63</span>
        <span class="site-state-item-name">카테고리</span></a>
      </div>
      <div class="site-state-item site-state-tags">
            <a href="/tags/">
          
        <span class="site-state-item-count">60</span>
        <span class="site-state-item-name">태그</span></a>
      </div>
  </nav>
</div>



      </section>
    </div>
  </aside>
  <div class="sidebar-dimmer"></div>


    </header>

    
  <div class="back-to-top">
    <i class="fa fa-arrow-up"></i>
    <span>0%</span>
  </div>
  <div class="reading-progress-bar"></div>

<noscript>
  <div class="noscript-warning">Theme NexT works best with JavaScript enabled</div>
</noscript>


    <div class="main-inner post posts-expand">
      

      

    
  
  
  <article itemscope="" itemtype="http://schema.org/Article" class="post-block" lang="study">
    <link itemprop="mainEntityOfPage" href="https://ejpark78.github.io/ckf3rmlfm003ak78oaqwe063g.html">

    <span hidden="" itemprop="author" itemscope="" itemtype="http://schema.org/Person">
      <meta itemprop="image" content="/images/avatar.gif">
      <meta itemprop="name" content="Park Eunjin">
      <meta itemprop="description" content="적자생존!">
    </span>

    <span hidden="" itemprop="publisher" itemscope="" itemtype="http://schema.org/Organization">
      <meta itemprop="name" content="오늘은 뭘 배우셨나요?">
    </span>

    
    
      <header class="post-header">
        <h1 class="post-title" itemprop="name headline">
          자연어 처리와 컴퓨터 언어학
        </h1>

        <div class="post-meta">
            <span class="post-meta-item">
              <span class="post-meta-item-icon">
                <i class="far fa-calendar"></i>
              </span>
              <span class="post-meta-item-text">작성일</span>

              <time title="Post created: 2020-08-18 21:36:52" itemprop="dateCreated datePublished" datetime="2020-08-18T21:36:52+09:00">2020-08-18</time>
            </span>
              <span class="post-meta-item">
                <span class="post-meta-item-icon">
                  <i class="far fa-calendar-check"></i>
                </span>
                <span class="post-meta-item-text">Edited on</span>
                <time title="Updated at: 2020-08-20 08:15:20" itemprop="dateModified" datetime="2020-08-20T08:15:20+09:00">2020-08-20</time>
              </span>
            <span class="post-meta-item">
              <span class="post-meta-item-icon">
                <i class="far fa-folder"></i>
              </span>
              <span class="post-meta-item-text">In</span>
                <span itemprop="about" itemscope="" itemtype="http://schema.org/Thing">
                  <a href="/categories/%EA%B3%B5%EB%B6%80/" itemprop="url" rel="index"><span itemprop="name">공부</span></a>
                </span>
                  , 
                <span itemprop="about" itemscope="" itemtype="http://schema.org/Thing">
                  <a href="/categories/%EA%B3%B5%EB%B6%80/%EC%9E%90%EC%97%B0%EC%96%B4-%EC%B2%98%EB%A6%AC%EC%99%80-%EC%BB%B4%ED%93%A8%ED%84%B0-%EC%96%B8%EC%96%B4%ED%95%99/" itemprop="url" rel="index"><span itemprop="name">자연어 처리와 컴퓨터 언어학</span></a>
                </span>
            </span>

          

        </div>
      </header>

    
    
    
    <div class="post-body" itemprop="articleBody">
        <figure class="highlight python"><table><tbody><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br><span class="line">27</span><br><span class="line">28</span><br><span class="line">29</span><br><span class="line">30</span><br><span class="line">31</span><br><span class="line">32</span><br><span class="line">33</span><br><span class="line">34</span><br><span class="line">35</span><br><span class="line">36</span><br><span class="line">37</span><br><span class="line">38</span><br><span class="line">39</span><br><span class="line">40</span><br><span class="line">41</span><br><span class="line">42</span><br><span class="line">43</span><br><span class="line">44</span><br><span class="line">45</span><br><span class="line">46</span><br></pre></td><td class="code"><pre><span class="line"><span class="keyword">from</span> gensim <span class="keyword">import</span> models</span><br><span class="line"><span class="keyword">import</span> spacy</span><br><span class="line"><span class="keyword">from</span> gensim <span class="keyword">import</span> corpora</span><br><span class="line"> </span><br><span class="line">documents = [</span><br><span class="line">    <span class="string">u"Football club Arsenal defeat local rivals this weekend."</span>,</span><br><span class="line">    <span class="string">u"Weekend football frenzy takes over London."</span>,</span><br><span class="line">    <span class="string">u"Bank open for take over bids after losing millions."</span>,</span><br><span class="line">    <span class="string">u"London football clubs bid to move to Wembley stadium."</span>,</span><br><span class="line">    <span class="string">u"Arsenal bid 50 million pounds for striker Kane."</span>,</span><br><span class="line">    <span class="string">u"Financial troubles result in loss of millions for bank."</span>,</span><br><span class="line">    <span class="string">u"Western bank files for bankruptcy after financial losses."</span>,</span><br><span class="line">    <span class="string">u"London football club is taken over by oil millionaire from Russia."</span>,</span><br><span class="line">    <span class="string">u"Banking on finances not working for Russia."</span>,</span><br><span class="line">]</span><br><span class="line"> </span><br><span class="line">nlp = spacy.load(<span class="string">"en"</span>)</span><br><span class="line">texts = []</span><br><span class="line"><span class="keyword">for</span> document <span class="keyword">in</span> documents:</span><br><span class="line">    text = []</span><br><span class="line">    doc = nlp(document)</span><br><span class="line">    <span class="keyword">for</span> w <span class="keyword">in</span> doc:</span><br><span class="line">        <span class="keyword">if</span> <span class="keyword">not</span> w.is_stop <span class="keyword">and</span> <span class="keyword">not</span> w.is_punct <span class="keyword">and</span> <span class="keyword">not</span> w.like_num:</span><br><span class="line">            text.append(w.lemma_)</span><br><span class="line">    texts.append(text)</span><br><span class="line"> </span><br><span class="line">dictionary = corpora.Dictionary(texts)</span><br><span class="line">print(dictionary.token2id)</span><br><span class="line"> </span><br><span class="line">corpus = [dictionary.doc2bow(text) <span class="keyword">for</span> text <span class="keyword">in</span> texts]</span><br><span class="line"> </span><br><span class="line"><span class="comment"># TF-IDF representation</span></span><br><span class="line">tfidf = models.TfidfModel(corpus)</span><br><span class="line"> </span><br><span class="line"><span class="keyword">for</span> document <span class="keyword">in</span> tfidf[corpus]:</span><br><span class="line">    <span class="keyword">print</span> document</span><br><span class="line"> </span><br><span class="line"><span class="comment"># n-grams 모델을 생성한다.</span></span><br><span class="line">bigram = gensim.models.Phrases(texts)</span><br><span class="line">texts = [bigram[line] <span class="keyword">for</span> line <span class="keyword">in</span> texts]</span><br><span class="line"> </span><br><span class="line">dictionary = Dictionary(texts)</span><br><span class="line">corpus = [dictionary.doc2bow(text) <span class="keyword">for</span> text <span class="keyword">in</span> texts]</span><br><span class="line"> </span><br><span class="line"><span class="comment"># 20개 문서 미만 또는 50% 이상의 문서에서 존재하는 단어들을 제거한다.</span></span><br><span class="line">dictionary.filter_extremes(no_below=<span class="number">20</span>, no_above=<span class="number">0.5</span>)</span><br></pre></td></tr></tbody></table></figure>
<ul>
<li>
<p>POS Tagging (State of the art): 다중 데이터셋으로 신경망을 이용해 도달한 결과</p>
<ul>
<li><a target="_blank" rel="noopener" href="https://aclweb.org/aclwiki/POS_Tagging_(State_of_the_art)">https://aclweb.org/aclwiki/POS_Tagging_(State_of_the_art)</a></li>
</ul>
</li>
<li>
<p>AI 의 살제: 파이썬으로 품사의 식별</p>
<ul>
<li><a target="_blank" rel="noopener" href="https://medium.com/@brianray_7981/ai-in-practice-identifying-parts-of-speech-in-python-8a690c7a1a08">https://medium.com/@brianray_7981/ai-in-practice-identifying-parts-of-speech-in-python-8a690c7a1a08</a></li>
</ul>
</li>
</ul>
<figure class="highlight python"><table><tbody><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br></pre></td><td class="code"><pre><span class="line"><span class="keyword">import</span> re</span><br><span class="line"><span class="keyword">from</span> collections <span class="keyword">import</span> Counter</span><br><span class="line"> </span><br><span class="line">words = re.findall(<span class="string">r'\w+'</span>, open(<span class="string">'hamlet.txt'</span>).read().lower())</span><br><span class="line">Counter(words).most_common(<span class="number">10</span>)</span><br></pre></td></tr></tbody></table></figure>
<ul>
<li>
<p><a target="_blank" rel="noopener" href="https://nlpforhackers.io/named-entity-extraction/">A complete guide to build your own Named Entity Recognizer with Python</a></p>
</li>
<li>
<p><a target="_blank" rel="noopener" href="https://www.depends-on-the-definition.com/introduction-named-entity-recognition-python/">Introduction To Named Entity Recognition In Python</a></p>
</li>
<li>
<p><a target="_blank" rel="noopener" href="http://www.albertauyeung.com/post/python-sequence-labelling-with-crf/">Performing Sequence Labelling using CRF in Python</a></p>
</li>
<li>
<p><a target="_blank" rel="noopener" href="https://explosion.ai/demos/displacy">dispaCy</a></p>
</li>
</ul>
<p>지역 구문 분석과 의존 구문 분석은 첫 번째 문장을 분할할 때부터 서로 다르다. 지역 구문 분석은 문장을 주제와 목적으로 분리하는데, 이는 보통 명사 구와 동사 구가 된다. 반면 의존 구문 분석은 동사를 문장의 머리 부분으로 간주하고 모든 의존성이 이를 중심으로 주변에 위치한다.</p>
<figure class="highlight python"><table><tbody><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br><span class="line">27</span><br><span class="line">28</span><br></pre></td><td class="code"><pre><span class="line"><span class="comment"># we need to first set up the text and corpus as it was done in section 3.3</span></span><br><span class="line"><span class="comment"># this refers to the code set-up in the Chapter 3</span></span><br><span class="line"> </span><br><span class="line"><span class="keyword">from</span> gensim.models <span class="keyword">import</span> LdaModel</span><br><span class="line"> </span><br><span class="line">ldamodel = LdaModel(corpus=corpus, num_topics=<span class="number">10</span>, id2word=dictionary)</span><br><span class="line">ldamodel.show_topics()</span><br><span class="line"> </span><br><span class="line">lsimodel = LsiModel(corpus=corpus, num_topics=<span class="number">10</span>, id2word=dictionary)</span><br><span class="line">lsimodel.show_topics(num_topics=<span class="number">5</span>)  <span class="comment"># Showing only the top 5 topics</span></span><br><span class="line"> </span><br><span class="line"><span class="comment"># 젠심을 이용할 때 자주 자주 사용되는 토픽 모델링 알고리즘은 HDP다.</span></span><br><span class="line"><span class="comment"># 비모수적 방법(non-parametric)이기 때문에 주제수를 지정할 필요가 없다.</span></span><br><span class="line">hdpmodel = HdpModel(corpus=corpus, id2word=dictionary)</span><br><span class="line">hdpmodel.show_topics()</span><br><span class="line"> </span><br><span class="line"> </span><br><span class="line"><span class="keyword">from</span> sklearn.decomposition <span class="keyword">import</span> NMF, LatentDirichletAllocation</span><br><span class="line">nmf = NMF(n_components=no_topic).fit(tfidf_corpus)</span><br><span class="line">lda = LatentDirichletAllocation(n_topics=no_topics).fit(tf_corpus)</span><br><span class="line"> </span><br><span class="line"><span class="function"><span class="keyword">def</span> <span class="title">display_topics</span>(<span class="params">model, feature_names, no_top_words</span>):</span></span><br><span class="line">    <span class="keyword">for</span> topic_idx, topic <span class="keyword">in</span> enumerate(model.components_):</span><br><span class="line">        <span class="keyword">print</span> <span class="string">"Topic %d:"</span> % (topic_idx)</span><br><span class="line">        <span class="keyword">print</span> <span class="string">" "</span>.join([feature_names[i]</span><br><span class="line">                        <span class="keyword">for</span> i <span class="keyword">in</span> topic.argsort()[:-no_top_words - <span class="number">1</span>:<span class="number">-1</span>]])</span><br><span class="line"> </span><br><span class="line">display_topics(nmf, tfidf_feature_names, no_top_words)</span><br></pre></td></tr></tbody></table></figure>
<figure class="highlight python"><table><tbody><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br><span class="line">27</span><br><span class="line">28</span><br><span class="line">29</span><br><span class="line">30</span><br><span class="line">31</span><br><span class="line">32</span><br><span class="line">33</span><br><span class="line">34</span><br><span class="line">35</span><br><span class="line">36</span><br><span class="line">37</span><br><span class="line">38</span><br><span class="line">39</span><br><span class="line">40</span><br><span class="line">41</span><br><span class="line">42</span><br><span class="line">43</span><br><span class="line">44</span><br><span class="line">45</span><br><span class="line">46</span><br><span class="line">47</span><br><span class="line">48</span><br><span class="line">49</span><br><span class="line">50</span><br><span class="line">51</span><br><span class="line">52</span><br><span class="line">53</span><br><span class="line">54</span><br><span class="line">55</span><br><span class="line">56</span><br><span class="line">57</span><br><span class="line">58</span><br><span class="line">59</span><br><span class="line">60</span><br><span class="line">61</span><br><span class="line">62</span><br><span class="line">63</span><br><span class="line">64</span><br><span class="line">65</span><br><span class="line">66</span><br></pre></td><td class="code"><pre><span class="line"><span class="comment"># pre-processing tips</span></span><br><span class="line"> </span><br><span class="line"><span class="comment"># adding stop words in spacy</span></span><br><span class="line"><span class="comment"># remember to load your appropriate language model</span></span><br><span class="line"> </span><br><span class="line">my_stop_words = [<span class="string">u'say'</span>, <span class="string">u'\'s'</span>, <span class="string">u'Mr'</span>, <span class="string">u'be'</span>, <span class="string">u'said'</span>, <span class="string">u'says'</span>, <span class="string">u'saying'</span>]</span><br><span class="line"><span class="keyword">for</span> stopword <span class="keyword">in</span> my_stop_words:</span><br><span class="line">    lexeme = nlp.vocab[stopword]</span><br><span class="line">    lexeme.is_stop = <span class="literal">True</span></span><br><span class="line"> </span><br><span class="line"><span class="comment"># adding logging</span></span><br><span class="line"><span class="comment"># 젠심의 학습 진행 상태 표시 설정</span></span><br><span class="line"><span class="keyword">import</span> logging</span><br><span class="line">logging.basicConfig(filename=<span class="string">'logfile.log'</span>, format=<span class="string">'%(asctime)s : %(levelname)s : %(message)s'</span>, level=logging.INFO)</span><br><span class="line"> </span><br><span class="line"> </span><br><span class="line"><span class="comment"># document - topic proportions</span></span><br><span class="line">ldamodel[corpus[<span class="number">0</span>]]</span><br><span class="line"> </span><br><span class="line"><span class="comment"># printing first topic</span></span><br><span class="line"> </span><br><span class="line">ldamodel.show_topics()[<span class="number">1</span>]</span><br><span class="line"> </span><br><span class="line">texts = [[<span class="string">'bank'</span>,<span class="string">'river'</span>,<span class="string">'shore'</span>,<span class="string">'water'</span>],</span><br><span class="line">        [<span class="string">'river'</span>,<span class="string">'water'</span>,<span class="string">'flow'</span>,<span class="string">'fast'</span>,<span class="string">'tree'</span>],</span><br><span class="line">        [<span class="string">'bank'</span>,<span class="string">'water'</span>,<span class="string">'fall'</span>,<span class="string">'flow'</span>],</span><br><span class="line">        [<span class="string">'bank'</span>,<span class="string">'bank'</span>,<span class="string">'water'</span>,<span class="string">'rain'</span>,<span class="string">'river'</span>],</span><br><span class="line">        [<span class="string">'river'</span>,<span class="string">'water'</span>,<span class="string">'mud'</span>,<span class="string">'tree'</span>],</span><br><span class="line">        [<span class="string">'money'</span>,<span class="string">'transaction'</span>,<span class="string">'bank'</span>,<span class="string">'finance'</span>],</span><br><span class="line">        [<span class="string">'bank'</span>,<span class="string">'borrow'</span>,<span class="string">'money'</span>],</span><br><span class="line">        [<span class="string">'bank'</span>,<span class="string">'finance'</span>],</span><br><span class="line">        [<span class="string">'finance'</span>,<span class="string">'money'</span>,<span class="string">'sell'</span>,<span class="string">'bank'</span>],</span><br><span class="line">        [<span class="string">'borrow'</span>,<span class="string">'sell'</span>],</span><br><span class="line">        [<span class="string">'bank'</span>,<span class="string">'loan'</span>,<span class="string">'sell'</span>]]</span><br><span class="line"> </span><br><span class="line">model.get_term_topics(<span class="string">'water'</span>)</span><br><span class="line">model.get_term_topics(<span class="string">'finance'</span>)</span><br><span class="line"> </span><br><span class="line">bow_water = [<span class="string">'bank'</span>,<span class="string">'water'</span>,<span class="string">'bank'</span>]</span><br><span class="line">bow_finance = [<span class="string">'bank'</span>,<span class="string">'finance'</span>,<span class="string">'bank'</span>]</span><br><span class="line">bow = model.id2word.doc2bow(bow_water) <span class="comment"># convert to bag of words format first</span></span><br><span class="line">doc_topics, word_topics, phi_values = model.get_document_topics(bow, per_word_topics=<span class="literal">True</span>)</span><br><span class="line"> </span><br><span class="line"><span class="comment"># coherence models: 주제 일관성 </span></span><br><span class="line"> </span><br><span class="line">lsi_coherence = CoherenceModel(topics=lsitopics[:<span class="number">10</span>], texts=texts, dictionary=dictionary, window_size=<span class="number">10</span>)</span><br><span class="line">hdp_coherence = CoherenceModel(topics=hdptopics[:<span class="number">10</span>], texts=texts, dictionary=dictionary, window_size=<span class="number">10</span>)</span><br><span class="line">lda_coherence = CoherenceModel(topics=ldatopics, texts=texts, dictionary=dictionary, window_size=<span class="number">10</span>)</span><br><span class="line"> </span><br><span class="line"><span class="comment"># train two models, one poorly trained (1 pass), and one trained with more passes (50 passes)</span></span><br><span class="line"><span class="comment"># 토픽 모델 평가</span></span><br><span class="line"> </span><br><span class="line">print(goodcm.get_coherence())</span><br><span class="line">print(badcm.get_coherence())</span><br><span class="line"> </span><br><span class="line"><span class="comment"># 말뭉치에 대한 최적의 주제 수를 예측하기 위해 일관성 측정 방법을 사용할 수도 있다.</span></span><br><span class="line">c_v = []</span><br><span class="line"><span class="keyword">for</span> num_topics <span class="keyword">in</span> range(<span class="number">1</span>, limit):</span><br><span class="line">        lm = LdaModel(corpus=corpus, num_topics=num_topics, id2word=dictionary)</span><br><span class="line">        cm = CoherenceModel(model=lm, texts=texts, dictionary=dictionary,          coherence=<span class="string">'c_v'</span>)</span><br><span class="line">        c_v.append(cm.get_coherence())</span><br><span class="line"> </span><br><span class="line"><span class="comment"># visualisation</span></span><br><span class="line"> </span><br><span class="line"><span class="keyword">import</span> pyLDAvis.gensim</span><br><span class="line">pyLDAvis.gensim.prepare(lda, corpus, dictionary)</span><br></pre></td></tr></tbody></table></figure>
<ul>
<li>
<p>논문과 소스코드: <a target="_blank" rel="noopener" href="https://paperswithcode.com/">https://paperswithcode.com/</a></p>
</li>
<li>
<p>대화체에 유연한 띄어쓰기 모델 만들기:  <a target="_blank" rel="noopener" href="https://blog.pingpong.us/spacing/?fbclid=IwAR2osQRhjNiSI4Ms5a-0mjXExW5_osqzvMx5iwF1r1tpkjn_s4_Dm0XsJYI">https://blog.pingpong.us/spacing/?fbclid=IwAR2osQRhjNiSI4Ms5a-0mjXExW5_osqzvMx5iwF1r1tpkjn_s4_Dm0XsJYI</a></p>
</li>
<li>
<p>pyLDAvis 튜토리얼</p>
<ul>
<li><a target="_blank" rel="noopener" href="https://github.com/bmabey/pyLDAvis/blob/master/notebooks/pyLDAvis_overview.ipynb">https://github.com/bmabey/pyLDAvis/blob/master/notebooks/pyLDAvis_overview.ipynb</a></li>
</ul>
</li>
<li>
<p>Visdom 서버: 테이터를 시작화하는데 도움이 되도록 특별히 제작된 파이썬 기반의 서버이다.</p>
<ul>
<li><a target="_blank" rel="noopener" href="https://github.com/facebookresearch/visdom">https://github.com/facebookresearch/visdom</a></li>
</ul>
</li>
</ul>
<p><a target="_blank" rel="noopener" href="https://nbviewer.jupyter.org/github/bmabey/pyLDAvis/blob/master/notebooks/pyLDAvis_overview.ipynb">https://nbviewer.jupyter.org/github/bmabey/pyLDAvis/blob/master/notebooks/pyLDAvis_overview.ipynb</a><br>
<a target="_blank" rel="noopener" href="https://nbviewer.jupyter.org/github/bmabey/pyLDAvis/blob/master/notebooks/Gensim%20Newsgroup.ipynb">https://nbviewer.jupyter.org/github/bmabey/pyLDAvis/blob/master/notebooks/Gensim Newsgroup.ipynb</a></p>
<ul>
<li>
<p>Word2Vec 군집화</p>
<ul>
<li><a target="_blank" rel="noopener" href="https://nbviewer.jupyter.org/github/RaRe-Technologies/gensim/blob/da383bf4a4046b134d95d9085eedb163dd5e0c46/docs/notebooks/Tensorboard_visualizations.ipynb">https://nbviewer.jupyter.org/github/RaRe-Technologies/gensim/blob/da383bf4a4046b134d95d9085eedb163dd5e0c46/docs/notebooks/Tensorboard_visualizations.ipynb</a></li>
<li><a target="_blank" rel="noopener" href="https://github.com/RaRe-Technologies/gensim/blob/develop/docs/notebooks/Tensorboard_visualizations.ipynb">https://github.com/RaRe-Technologies/gensim/blob/develop/docs/notebooks/Tensorboard_visualizations.ipynb</a></li>
<li><a target="_blank" rel="noopener" href="https://nbviewer.jupyter.org/github/RaRe-Technologies/gensim/tree/da383bf4a4046b134d95d9085eedb163dd5e0c46/docs/notebooks/">https://nbviewer.jupyter.org/github/RaRe-Technologies/gensim/tree/da383bf4a4046b134d95d9085eedb163dd5e0c46/docs/notebooks/</a></li>
</ul>
</li>
<li>
<p>10장 텍스트 군집화 및 분류</p>
</li>
</ul>
<figure class="highlight python"><table><tbody><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br><span class="line">27</span><br><span class="line">28</span><br><span class="line">29</span><br><span class="line">30</span><br><span class="line">31</span><br><span class="line">32</span><br><span class="line">33</span><br><span class="line">34</span><br><span class="line">35</span><br><span class="line">36</span><br><span class="line">37</span><br><span class="line">38</span><br><span class="line">39</span><br><span class="line">40</span><br><span class="line">41</span><br><span class="line">42</span><br><span class="line">43</span><br><span class="line">44</span><br><span class="line">45</span><br><span class="line">46</span><br><span class="line">47</span><br><span class="line">48</span><br><span class="line">49</span><br><span class="line">50</span><br><span class="line">51</span><br><span class="line">52</span><br><span class="line">53</span><br><span class="line">54</span><br><span class="line">55</span><br><span class="line">56</span><br><span class="line">57</span><br><span class="line">58</span><br><span class="line">59</span><br><span class="line">60</span><br><span class="line">61</span><br><span class="line">62</span><br><span class="line">63</span><br><span class="line">64</span><br><span class="line">65</span><br><span class="line">66</span><br><span class="line">67</span><br><span class="line">68</span><br><span class="line">69</span><br><span class="line">70</span><br><span class="line">71</span><br><span class="line">72</span><br><span class="line">73</span><br><span class="line">74</span><br><span class="line">75</span><br><span class="line">76</span><br><span class="line">77</span><br><span class="line">78</span><br><span class="line">79</span><br><span class="line">80</span><br><span class="line">81</span><br><span class="line">82</span><br><span class="line">83</span><br><span class="line">84</span><br><span class="line">85</span><br></pre></td><td class="code"><pre><span class="line"><span class="keyword">from</span> sklearn.datasets <span class="keyword">import</span> fetch_20newsgroups</span><br><span class="line"> </span><br><span class="line">categories = [</span><br><span class="line">    <span class="string">'alt.atheism'</span>,</span><br><span class="line">    <span class="string">'talk.religion.misc'</span>,</span><br><span class="line">    <span class="string">'comp.graphics'</span>,</span><br><span class="line">    <span class="string">'sci.space'</span>,</span><br><span class="line">]</span><br><span class="line"> </span><br><span class="line">dataset = fetch_20newsgroups(subset=<span class="string">'all'</span>, categories=categories, shuffle=<span class="literal">True</span>, random_state=<span class="number">42</span>)</span><br><span class="line"> </span><br><span class="line">labels = dataset.target</span><br><span class="line">true_k = np.unique(labels).shape[<span class="number">0</span>]</span><br><span class="line">data = dataset.data </span><br><span class="line"> </span><br><span class="line"><span class="keyword">from</span> sklearn.feature_extraction.text <span class="keyword">import</span> TfidfVectorizer</span><br><span class="line"> </span><br><span class="line">vectorizer = TfidfVectorizer(max_df=<span class="number">0.5</span>, min_df=<span class="number">2</span>, stop_words=<span class="string">'english'</span>, use_idf=<span class="literal">True</span>)</span><br><span class="line"> </span><br><span class="line">X = vectorizer.fit_transform(data)</span><br><span class="line"> </span><br><span class="line"> </span><br><span class="line"><span class="keyword">from</span> sklearn.decomposition <span class="keyword">import</span> PCA</span><br><span class="line"> </span><br><span class="line"> </span><br><span class="line">newsgroups_train = fetch_20newsgroups(subset=<span class="string">'train'</span>,</span><br><span class="line">                                      categories=[<span class="string">'alt.atheism'</span>, <span class="string">'sci.space'</span>])</span><br><span class="line">pipeline = Pipeline([</span><br><span class="line">    (<span class="string">'vect'</span>, CountVectorizer()),</span><br><span class="line">    (<span class="string">'tfidf'</span>, TfidfTransformer()),</span><br><span class="line">])       </span><br><span class="line">X_visualise = pipeline.fit_transform(newsgroups_train.data).todense()</span><br><span class="line"> </span><br><span class="line">pca = PCA(n_components=<span class="number">2</span>).fit(X_visualise)</span><br><span class="line">data2D = pca.transform(X_visualise)</span><br><span class="line">plt.scatter(data2D[:,<span class="number">0</span>], data2D[:,<span class="number">1</span>], c=newsgroups_train.target)</span><br><span class="line"> </span><br><span class="line"><span class="comment"># 특이값 분해로 차원 축소</span></span><br><span class="line"> </span><br><span class="line">n_components = <span class="number">5</span></span><br><span class="line">svd = TruncatedSVD(n_components)</span><br><span class="line">normalizer = Normalizer(copy=<span class="literal">False</span>)</span><br><span class="line">lsa = make_pipeline(svd, normalizer)</span><br><span class="line"> </span><br><span class="line">X = lsa.fit_transform(X)</span><br><span class="line"> </span><br><span class="line"> </span><br><span class="line">Minibatch = <span class="literal">True</span></span><br><span class="line"><span class="keyword">if</span> minibatch:</span><br><span class="line">    km = MiniBatchKMeans(n_clusters=true_k, init=<span class="string">'k-means++'</span>, n_init=<span class="number">1</span>, init_size=<span class="number">1000</span>, batch_size=<span class="number">1000</span>)</span><br><span class="line"><span class="keyword">else</span>:</span><br><span class="line">    km = KMeans(n_clusters=true_k, init=<span class="string">'k-means++'</span>, max_iter=<span class="number">100</span>, n_init=<span class="number">1</span>)</span><br><span class="line">km.fit(X)</span><br><span class="line"> </span><br><span class="line">original_space_centroids = svd.inverse_transform(km.cluster_centers_)</span><br><span class="line"> </span><br><span class="line">order_centroids = original_space_centroids.argsort()[:, ::<span class="number">-1</span>]</span><br><span class="line"> </span><br><span class="line"><span class="comment"># [The above bit of code is necessary because of our LSI transformation]</span></span><br><span class="line"> </span><br><span class="line">terms = vectorizer.get_feature_names()</span><br><span class="line"> </span><br><span class="line"><span class="keyword">for</span> i <span class="keyword">in</span> range(true_k):</span><br><span class="line">    print(<span class="string">"Cluster %d:"</span> % i)</span><br><span class="line">    <span class="keyword">for</span> ind <span class="keyword">in</span> order_centroids[i, :<span class="number">10</span>]:</span><br><span class="line">        print(<span class="string">' %s'</span> % terms[ind])</span><br><span class="line"> </span><br><span class="line"><span class="keyword">from</span> sklearn.metrics.pairwise <span class="keyword">import</span> cosine_similarity</span><br><span class="line">dist = <span class="number">1</span> - cosine_similarity(X)</span><br><span class="line"> </span><br><span class="line"><span class="keyword">from</span> scipy.cluster.hierarchy <span class="keyword">import</span> ward, dendrogram</span><br><span class="line"> </span><br><span class="line">linkage_matrix = ward(dist)</span><br><span class="line">fig, ax = plt.subplots(figsize=(<span class="number">10</span>, <span class="number">15</span>)) <span class="comment"># set size</span></span><br><span class="line">ax = dendrogram(linkage_matrix, orientation=<span class="string">"right"</span>)</span><br><span class="line"> </span><br><span class="line"><span class="comment"># classification</span></span><br><span class="line"> </span><br><span class="line"><span class="keyword">from</span> sklearn.naive_bayes <span class="keyword">import</span> GaussianNB</span><br><span class="line">gnb = GaussianNB()</span><br><span class="line">gnb.fit(X, labels)</span><br><span class="line"> </span><br><span class="line"><span class="keyword">from</span> sklearn.svm <span class="keyword">import</span> SVC</span><br><span class="line">svm = SVC()</span><br><span class="line">svm.fit(X, labels)</span><br></pre></td></tr></tbody></table></figure>
<ul>
<li>
<p>Automatic Topic Clustering Using Doc2Vec</p>
<ul>
<li><a target="_blank" rel="noopener" href="https://towardsdatascience.com/automatic-topic-clustering-using-doc2vec-e1cea88449c">https://towardsdatascience.com/automatic-topic-clustering-using-doc2vec-e1cea88449c</a></li>
</ul>
</li>
<li>
<p>GridSearchCV</p>
<ul>
<li><a target="_blank" rel="noopener" href="https://scikit-learn.org/stable/auto_examples/model_selection/plot_grid_search_digits.html">https://scikit-learn.org/stable/auto_examples/model_selection/plot_grid_search_digits.html</a></li>
</ul>
</li>
<li>
<p>Text Classification with Word2Vec:</p>
<ul>
<li><a target="_blank" rel="noopener" href="http://nadbordrozd.github.io/blog/2016/05/20/text-classification-with-word2vec/">http://nadbordrozd.github.io/blog/2016/05/20/text-classification-with-word2vec/</a></li>
</ul>
</li>
<li>
<p>11장 유사 질의 및 요약</p>
</li>
</ul>
<figure class="highlight python"><table><tbody><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br><span class="line">27</span><br><span class="line">28</span><br><span class="line">29</span><br><span class="line">30</span><br><span class="line">31</span><br><span class="line">32</span><br><span class="line">33</span><br><span class="line">34</span><br><span class="line">35</span><br><span class="line">36</span><br><span class="line">37</span><br><span class="line">38</span><br><span class="line">39</span><br><span class="line">40</span><br><span class="line">41</span><br><span class="line">42</span><br><span class="line">43</span><br><span class="line">44</span><br><span class="line">45</span><br><span class="line">46</span><br><span class="line">47</span><br><span class="line">48</span><br><span class="line">49</span><br><span class="line">50</span><br><span class="line">51</span><br><span class="line">52</span><br><span class="line">53</span><br><span class="line">54</span><br><span class="line">55</span><br><span class="line">56</span><br><span class="line">57</span><br><span class="line">58</span><br><span class="line">59</span><br><span class="line">60</span><br><span class="line">61</span><br><span class="line">62</span><br><span class="line">63</span><br><span class="line">64</span><br><span class="line">65</span><br><span class="line">66</span><br><span class="line">67</span><br><span class="line">68</span><br><span class="line">69</span><br><span class="line">70</span><br><span class="line">71</span><br><span class="line">72</span><br><span class="line">73</span><br><span class="line">74</span><br><span class="line">75</span><br><span class="line">76</span><br><span class="line">77</span><br><span class="line">78</span><br><span class="line">79</span><br><span class="line">80</span><br><span class="line">81</span><br><span class="line">82</span><br><span class="line">83</span><br><span class="line">84</span><br><span class="line">85</span><br><span class="line">86</span><br><span class="line">87</span><br><span class="line">88</span><br><span class="line">89</span><br><span class="line">90</span><br><span class="line">91</span><br><span class="line">92</span><br><span class="line">93</span><br><span class="line">94</span><br><span class="line">95</span><br><span class="line">96</span><br></pre></td><td class="code"><pre><span class="line">texts = [[<span class="string">'bank'</span>,<span class="string">'river'</span>,<span class="string">'shore'</span>,<span class="string">'water'</span>],</span><br><span class="line">        [<span class="string">'river'</span>,<span class="string">'water'</span>,<span class="string">'flow'</span>,<span class="string">'fast'</span>,<span class="string">'tree'</span>],</span><br><span class="line">        [<span class="string">'bank'</span>,<span class="string">'water'</span>,<span class="string">'fall'</span>,<span class="string">'flow'</span>],</span><br><span class="line">        [<span class="string">'bank'</span>,<span class="string">'bank'</span>,<span class="string">'water'</span>,<span class="string">'rain'</span>,<span class="string">'river'</span>],</span><br><span class="line">        [<span class="string">'river'</span>,<span class="string">'water'</span>,<span class="string">'mud'</span>,<span class="string">'tree'</span>],</span><br><span class="line">        [<span class="string">'money'</span>,<span class="string">'transaction'</span>,<span class="string">'bank'</span>,<span class="string">'finance'</span>],</span><br><span class="line">        [<span class="string">'bank'</span>,<span class="string">'borrow'</span>,<span class="string">'money'</span>],</span><br><span class="line">        [<span class="string">'bank'</span>,<span class="string">'finance'</span>],</span><br><span class="line">        [<span class="string">'finance'</span>,<span class="string">'money'</span>,<span class="string">'sell'</span>,<span class="string">'bank'</span>],</span><br><span class="line">        [<span class="string">'borrow'</span>,<span class="string">'sell'</span>],</span><br><span class="line">        [<span class="string">'bank'</span>, <span class="string">'loan'</span>, <span class="string">'sell'</span>]</span><br><span class="line"> </span><br><span class="line">dictionary = Dictionary(texts)</span><br><span class="line">corpus = [dictionary.doc2bow(text) <span class="keyword">for</span> text <span class="keyword">in</span> texts]</span><br><span class="line"> </span><br><span class="line">tfidf = TfidfModel(corpus)</span><br><span class="line">model = ldamodel.LdaModel(corpus, id2word=dictionary, num_topics=<span class="number">2</span>)</span><br><span class="line"> </span><br><span class="line">model.show_topics()</span><br><span class="line"> </span><br><span class="line">doc_water = [<span class="string">'river'</span>, <span class="string">'water'</span>, <span class="string">'shore'</span>]</span><br><span class="line">doc_finance = [<span class="string">'finance'</span>, <span class="string">'money'</span>, <span class="string">'sell'</span>]</span><br><span class="line">doc_bank = [<span class="string">'finance'</span>, <span class="string">'bank'</span>, <span class="string">'tree'</span>, <span class="string">'water'</span>]</span><br><span class="line"> </span><br><span class="line">bow_water = model.id2word.doc2bow(doc_water)  </span><br><span class="line">bow_finance = model.id2word.doc2bow(doc_finance)  </span><br><span class="line">bow_bank = model.id2word.doc2bow(doc_bank)  </span><br><span class="line"> </span><br><span class="line">lda_bow_water = model[bow_water]</span><br><span class="line">lda_bow_finance = model[bow_finance]</span><br><span class="line">lda_bow_bank = model[bow_bank]</span><br><span class="line"> </span><br><span class="line">tfidf_bow_water = tfidf[bow_water]</span><br><span class="line">tfidf_bow_finance = tfidf[bow_finance]</span><br><span class="line">tfidf_bow_bank = tfidf[bow_bank]</span><br><span class="line"> </span><br><span class="line"><span class="keyword">from</span> gensim.matutils <span class="keyword">import</span> kullback_leibler, jaccard, hellinger</span><br><span class="line"> </span><br><span class="line">hellinger(lda_bow_water, lda_bow_finance)</span><br><span class="line">hellinger(lda_bow_finance, lda_bow_bank)</span><br><span class="line">hellinger(lda_bow_bank, lda_bow_water)</span><br><span class="line"> </span><br><span class="line">hellinger(lda_bow_finance, lda_bow_water)</span><br><span class="line">kullback_leibler(lda_bow_water, lda_bow_bank)</span><br><span class="line">kullback_leibler(lda_bow_bank, lda_bow_water)</span><br><span class="line"> </span><br><span class="line"> </span><br><span class="line">jaccard(bow_water, bow_bank)</span><br><span class="line">jaccard(doc_water, doc_bank)</span><br><span class="line">jaccard([<span class="string">'word'</span>], [<span class="string">'word'</span>])</span><br><span class="line"> </span><br><span class="line"><span class="function"><span class="keyword">def</span> <span class="title">make_topics_bow</span>(<span class="params">topic</span>):</span></span><br><span class="line">    <span class="comment"># takes the string returned by model.show_topics()</span></span><br><span class="line">    <span class="comment"># split on strings to get topics and the probabilities</span></span><br><span class="line">    topic = topic.split(<span class="string">'+'</span>)</span><br><span class="line">    <span class="comment"># list to store topic bows</span></span><br><span class="line">    topic_bow = []</span><br><span class="line">    <span class="keyword">for</span> word <span class="keyword">in</span> topic:</span><br><span class="line">        <span class="comment"># split probability and word</span></span><br><span class="line">        prob, word = word.split(<span class="string">'*'</span>)</span><br><span class="line">        <span class="comment"># get rid of spaces</span></span><br><span class="line">        word = word.replace(<span class="string">" "</span>,<span class="string">""</span>)</span><br><span class="line">        <span class="comment"># convert to word_type</span></span><br><span class="line">        word = model.id2word.doc2bow([word])[<span class="number">0</span>][<span class="number">0</span>]</span><br><span class="line">        topic_bow.append((word, float(prob)))</span><br><span class="line">    <span class="keyword">return</span> topic_bow</span><br><span class="line"> </span><br><span class="line"> </span><br><span class="line">topic_water, topic_finance = model.show_topics()</span><br><span class="line">finance_distribution = make_topics_bow(topic_finance[<span class="number">1</span>])</span><br><span class="line">water_distribution = make_topics_bow(topic_water[<span class="number">1</span>])</span><br><span class="line"> </span><br><span class="line">hellinger(water_distribution, finance_distribution)</span><br><span class="line"> </span><br><span class="line"><span class="keyword">from</span> gensim <span class="keyword">import</span> similarities</span><br><span class="line"> </span><br><span class="line">index = similarities.MatrixSimilarity(model[corpus])</span><br><span class="line">sims = index[lda_bow_finance]</span><br><span class="line">print(list(enumerate(sims)))</span><br><span class="line"> </span><br><span class="line">sims = sorted(enumerate(sims), key=<span class="keyword">lambda</span> item: -item[<span class="number">1</span>])</span><br><span class="line"> </span><br><span class="line"><span class="keyword">for</span> doc_id, similarity <span class="keyword">in</span> sims:</span><br><span class="line">    <span class="keyword">print</span> texts[doc_id], similarity</span><br><span class="line"> </span><br><span class="line"><span class="keyword">from</span> gensim.summarization <span class="keyword">import</span> summarize</span><br><span class="line"><span class="keyword">print</span> (summarize(text))</span><br><span class="line"> </span><br><span class="line"><span class="keyword">print</span> (summarize(text, word_count=<span class="number">50</span>))</span><br><span class="line"> </span><br><span class="line"><span class="keyword">from</span> gensim.summarization <span class="keyword">import</span> keywords</span><br><span class="line"> </span><br><span class="line"><span class="keyword">print</span> (keywords(text))</span><br><span class="line"> </span><br><span class="line"><span class="keyword">from</span> gensim.summarization <span class="keyword">import</span> mz_keywords</span><br><span class="line">mz_keywords(text,scores=<span class="literal">True</span>,weighted=<span class="literal">False</span>,threshold=<span class="number">1.0</span>)</span><br></pre></td></tr></tbody></table></figure>

    </div>

    
    
    

      <footer class="post-footer">
          <div class="post-tags">
              <a href="/tags/%EA%B3%B5%EB%B6%80/" rel="tag"># 공부</a>
              <a href="/tags/%EC%9E%90%EC%97%B0%EC%96%B4-%EC%B2%98%EB%A6%AC%EC%99%80-%EC%BB%B4%ED%93%A8%ED%84%B0-%EC%96%B8%EC%96%B4%ED%95%99/" rel="tag"># 자연어 처리와 컴퓨터 언어학</a>
          </div>

        

          <div class="post-nav">
            <div class="post-nav-item">
                <a href="/ckf3rmlf9002ok78oc0vr9b4z.html" rel="prev" title="몽고디비 덤프 v4.4">
                  <i class="fa fa-chevron-left"></i> 몽고디비 덤프 v4.4
                </a>
            </div>
            <div class="post-nav-item">
                <a href="/ckf3rmlf7002jk78oa2th4h5y.html" rel="next" title=".netrc를 이용한 curl 인증 정보 저장">
                  .netrc를 이용한 curl 인증 정보 저장 <i class="fa fa-chevron-right"></i>
                </a>
            </div>
          </div>
      </footer>
    
  </article>
  
  
  



      

<script>
  window.addEventListener('tabs:register', () => {
    let { activeClass } = CONFIG.comments;
    if (CONFIG.comments.storage) {
      activeClass = localStorage.getItem('comments_active') || activeClass;
    }
    if (activeClass) {
      const activeTab = document.querySelector(`a[href="#comment-${activeClass}"]`);
      if (activeTab) {
        activeTab.click();
      }
    }
  });
  if (CONFIG.comments.storage) {
    window.addEventListener('tabs:click', event => {
      if (!event.target.matches('.tabs-comment .tab-content .tab-pane')) return;
      const commentClass = event.target.classList[1];
      localStorage.setItem('comments_active', commentClass);
    });
  }
</script>

    </div>
  </main>

  <footer class="footer">
    <div class="footer-inner">
      

      

<div class="copyright">
  
  © 
  <span itemprop="copyrightYear">2020</span>
  <span class="with-love">
    <i class="fa fa-heart"></i>
  </span>
  <span class="author" itemprop="copyrightHolder">Park Eunjin</span>
</div>
  <div class="powered-by">Powered by <a href="https://hexo.io/" class="theme-link" rel="noopener" target="_blank">Hexo</a> &amp; <a href="https://theme-next.js.org/" class="theme-link" rel="noopener" target="_blank">NexT.Gemini</a>
  </div>

      








    </div>
  </footer>

  
  <script src="//cdn.jsdelivr.net/npm/animejs@3.2.0/lib/anime.min.js"></script>
  <script src="//cdn.jsdelivr.net/npm/@next-theme/pjax@0.4.0/pjax.min.js"></script>

  


  















    <div class="pjax">
  

  

  

    </div><!-- hexo-inject:begin --><!-- hexo-inject:end -->


<script src="/bundle.js"></script><script>
var pjax = new Pjax({
  selectors: [
    'head title',
    '.page-configurations',
    '.main-inner',
    '.post-toc-wrap',
    '.languages',
    '.pjax'
  ],
  analytics: false,
  cacheBust: false,
  scrollRestoration: false,
  scrollTo: !CONFIG.bookmark.enable
});

document.addEventListener('pjax:success', () => {
  pjax.executeScripts(document.querySelectorAll('script[data-pjax], .pjax script'));
  NexT.boot.refresh();
  // Define Motion Sequence & Bootstrap Motion.
  if (CONFIG.motion.enable) {
    NexT.motion.integrator
      .init()
      .add(NexT.motion.middleWares.subMenu)
      .add(NexT.motion.middleWares.postList)
      .bootstrap();
  }
  const hasTOC = document.querySelector('.post-toc');
  document.querySelector('.sidebar-inner').classList.toggle('sidebar-nav-active', hasTOC);
  document.querySelector(hasTOC ? '.sidebar-nav-toc' : '.sidebar-nav-overview').click();
  NexT.utils.updateSidebarPosition();
});
</script></body></html>